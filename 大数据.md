# 大数据

![mark](http://pic-cloud.ice-leaf.top/pic-cloud/20190313/7xIAJV9NTNBY.png?imageslim)

**核心思想**： 既然数据是庞大的，而程序要比数据小得多，将数据输入给程序是不划算的，那么就反其道而行之，**将程序分发到数据所在的地方进行计算，也就是所谓的移动计算比移动数据更划算。**

## 大数据存储HDFS
![mark](http://pic-cloud.ice-leaf.top/pic-cloud/20190315/6M7PWgSY8aQm.png?imageslim)

NameNode 是整个 HDFS 的核心，记录着 HDFS 文件分配表信息，所以 NameNode 高可用容错能力非常重要。
![mark](http://pic-cloud.ice-leaf.top/pic-cloud/20190315/hja3vhEB5T6b.png?imageslim)

一般说来，常用的保证系统可用性的策略有冗余备份、失效转移和降级（关闭部分功能，降低资源消耗）限流（拒绝部分请求）。

## MapReduce

**MapReduce 既是一个编程模型，又是一个计算框架。**
开发人员必须基于 MapReduce 编程模型进行编程开发，然后将程序通过 MapReduce 计算框架分发到 Hadoop 集群中运行。

### MapReduce 作业启动和运行机制
![mark](http://pic-cloud.ice-leaf.top/pic-cloud/20190315/b04MXOKEwCBr.png?imageslim)

要做的仅仅是编写一个 map 函数和一个 reduce 函数就可以了，根本不用关心这两个函数是如何被分布启动到集群上的，也不用关心数据块又是如何分配给计算任务的。**这一切都由 MapReduce 计算框架完成！**

### MapReduce 数据合并与连接机制
在 map 输出与 reduce 输入之间，MapReduce 计算框架处理数据合并与连接操作，这个操作有个专门的词汇叫**shuffle**。
![mark](http://pic-cloud.ice-leaf.top/pic-cloud/20190315/RcNKdTPQabgR.png?imageslim)
每个 Map 任务的计算结果都会写入到本地文件系统，等 Map 任务快要计算完成的时候，MapReduce 计算框架会启动 shuffle 过程，在 Map 任务进程调用一个 Partitioner 接口，对 Map 尝试的每个 <Key, Value> 进行 Reduce 分区选择，然后通过 HTTP 通信发送给对应的 Reduce 进程。这样不管 Map 位于哪个服务器节点，相同的 Key 一点会被发送给相同的 Reduce 进程。Reduce 任务进程对收到的 <Key, Value> 进行排序和合并，相同的 Key 放在一起，组成一个 <Key, Value集合> 传递给 Reduce 执行。
```java
 /** Use {@link Object#hashCode()} to partition. */ 
public int getPartition(K2 key, V2 value, int numReduceTasks) { 
    return (key.hashCode() & Integer.MAX_VALUE) % numReduceTasks; 
 }
```

## Yarn
分布式集群资源调度框架
![mark](http://pic-cloud.ice-leaf.top/pic-cloud/20190322/LG1U66AmJR0j.png?imageslim)
![mark](http://pic-cloud.ice-leaf.top/pic-cloud/20190322/vPA2w4yXlMFX.png?imageslim)

## Hive
![mark](http://pic-cloud.ice-leaf.top/pic-cloud/20190322/rnsStGLmnqhR.png?imageslim)
![mark](http://pic-cloud.ice-leaf.top/pic-cloud/20190322/51jjFjNgJ4Qv.png?imageslim)

将 Hive 的执行计划转换成 Spark 的计算模型，即 Hive on Spark。

## Spark




未完待续。。。